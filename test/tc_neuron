#!/usr/bin/env ruby
require 'test/unit'
require 'neuronet'

class TestNeuron < Test::Unit::TestCase
  include Neuronet

  def test_neuron
    neuron = Neuron.new
    assert_equal 'a:0', neuron.inspect
    assert_equal 'a', neuron.to_s
    assert_equal 0.0, neuron.value
    assert_equal 0.5, neuron.activation

    # bias is zero and there are no connection..
    assert_equal 0.5, neuron.partial
    assert_equal 0.5, neuron.update
    assert_equal 0.0, neuron.value
    assert_equal 0.5, neuron.activation

    # In order to isolate the backpropagate/update methods, we need to trick the
    # neuron into behaving as if it has a connection.
    c = neuron.connections
    def c.empty? = false

    Neuronet.noise = NO_NOISE
    assert_equal neuron, neuron.backpropagate(1.0)
    assert_equal 'a:0|1', neuron.inspect
    # update returns activation.
    assert_equal 0.731, neuron.update.round(3)
    assert_equal 'a:1|1', neuron.inspect
    Neuronet.noise = NOISE # Restore

    ###      :b         connect :c
    neuron = Neuron.new
    neuron.connect(Neuron.new)
    assert_equal 'b:0|0+0*c', neuron.inspect
    assert_equal 'b', neuron.to_s

    Neuron.label = 'a' # restore
  end

  def test_legacy
    output = Neuron.new
    3.times{ output.connect(weight: 1.0) }
    assert_equal 'a:0|0+1*b+1*c+1*d', output.inspect

    assert_equal 1+3*0.5, output.mu
    assert_equal 3*0.25*0.5, output.mju(&:activation)
    assert_equal (1-0.5)*0.5, output.derivative
    assert_equal (1-0.5)*0.5*(1+3*0.5), output.lamda
    assert_equal 0.0, output.kappa # kappa is level two.
    assert_equal 0.0, output.iota # iota is level three.

    ni = output.connections.first.neuron
    ni.connect(weight: 1.0)
    assert_equal 1*0.25*(1+0.5), output.kappa # 0.375
    assert_equal 0.0, output.iota # iota is level three.

    nj = ni.connections.first.neuron
    nj.connect(weight: 1.0)
    assert_equal 0.375, output.kappa # kappa is level two.
    assert_equal 1*0.25*0.375, output.iota # iota is level three.

    Neuron.label = 'a' # restore
  end

  def test_recursive_mju
    ff = FeedForward.new([12, 12, 12, 12])

    3.times do
      ff.each do |layer|
        layer.each do |neuron|
          next if neuron.connections.empty?
          neuron.bias = rand - rand
          neuron.connections.each do |connection|
            connection.weight = rand - rand
          end
        end
      end

      ff.last.each do |neuron|
        mju0 = (neuron.mu + neuron.kappa + neuron.iota).round(12)
        mju1 = Neuron.mju(neuron).round(12)
        assert_equal mju0, mju1
      end
    end

    Neuron.label = 'a' # restore
  end

  def test_value
    n = Neuron.new
    n.value = 1.0
    assert_equal 1.0, n.value
    assert_equal Neuronet::SQUASH[1], n.activation
    assert_equal 'a:1', n.inspect

    Neuron.label = 'a' # restore
  end

  def test_backpropagate
    Neuronet.noise = NO_NOISE
    Neuronet.format = '%.3g'

    a = Neuron.new
    b = a.connect
    c = b.connect
    d = c.connect

    assert_equal 'a:0|0+0*b', a.inspect
    assert_equal 'b:0|0+0*c', b.inspect
    assert_equal 'c:0|0+0*d', c.inspect
    assert_equal 'd:0', d.inspect

    a.backpropagate(1.0).update
    # a, b, and c are updated, changed.
    assert_equal 'a:1.4|1+0.5*b', a.inspect
    assert_equal 'b:1.39|1+0.5*c', b.inspect
    assert_equal 'c:1.25|1+0.5*d', c.inspect
    # d is input, remains unchanged.
    assert_equal 'd:0', d.inspect

    Neuron.label = 'a' # restore
    Neuronet.noise = NOISE
    Neuronet.format = FORMAT
  end
end
